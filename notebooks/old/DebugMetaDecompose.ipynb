{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.datasetdscr = datasetdscr\n",
    "import unified_ar.general.Cache as Cache\n",
    "Cache.GlobalDisable = True\n",
    "starts = s_events.time.dt.floor(self.meta_start_period).unique()\n",
    "ends = starts+self.meta_size\n",
    "\n",
    "meta_features = []\n",
    "meta_targets = []\n",
    "from constants import methods\n",
    "tmp_segments = methods.segmentation\n",
    "methods.segmentation = methods.meta_segmentation_sub_tasks\n",
    "self.segmentor_dic = {p['method']().shortname(): p for p in methods.meta_segmentation_sub_tasks}\n",
    "if 1:\n",
    "import ml_strategy.Simple\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "fast_strategy = ml_strategy.Simple.NormalStrategy()\n",
    "fast_strategy.ui_debug = {'seg': 0}\n",
    "for s, e in zip(starts, ends):\n",
    "    data2 = self.customSplit(s_events, a_events, s, e)\n",
    "    print(f's={s} : {e}============= #sevent={len(data2.s_events)} #aevents={len(data2.a_events)}')\n",
    "    if len(data2.s_events) == 0 or len(data2.a_events) == 0:\n",
    "        continue\n",
    "\n",
    "    result = fast_strategy.train(datasetdscr, data2, acts, update_model=True)\n",
    "    if result is None:\n",
    "        continue\n",
    "    logger.debug(fast_strategy.get_info().functions)\n",
    "    # result=fast_strategy.pipeline(fast_strategy.functions,self.traindata,train=True)\n",
    "    aggr = data2.s_events.groupby('SID').count()\n",
    "    fea = {k: aggr.loc[k]['value'] if k in aggr.index else 0 for k in datasetdscr.sensor_id_map_inverse}\n",
    "    fea['time'] = s\n",
    "    meta_features.append(fea)\n",
    "    seg = result.functions['segmentor']\n",
    "    meta_targets.append({'method': seg[0], **result.quality, **{p: seg[1][p] for p in seg[1]}})\n",
    "    # self.strategy=fast_strategy\n",
    "methods.segmentation = tmp_segments\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "d = {'meta_features': meta_features, 'meta_targets': meta_targets}\n",
    "import unified_ar.general.utils\n",
    "from constants import methods\n",
    "general.utils.saveState(d, f\"meta_dataset/{methods.run_names['out']} {methods.run_names['fold']}\")\n",
    "else:\n",
    "import unified_ar.general.utils\n",
    "d = general.utils.loadState(\n",
    "    \"meta_dataset 220602_23-52-11-A4H-Namespace(classifier=0, comment='0', dataset=3, evaluation=0, feature_extraction=0, mlstrategy=0, output='logs', segmentation=0) 0\")\n",
    "\n",
    "feat_df = pd.DataFrame(d['meta_features'])\n",
    "target_df = pd.DataFrame(d['meta_targets'])\n",
    "# print(feat_df.describe())\n",
    "ntarget = target_df.drop(['accuracy', 'precision', 'recall', 'f1'], axis=1)\n",
    "\n",
    "self.targetTransformer = MyTargetTransformer(self.meta_mode)\n",
    "self.targetTransformer.fit(ntarget)\n",
    "self.featTransformer = self.create_feat_transformer(feat_df)\n",
    "self.featTransformer.fit(feat_df)\n",
    "print(f\"metainfo=============== \\nfeat={feat_df}\\n target={target_df}\")\n",
    "X = self.featTransformer.transform(feat_df)\n",
    "y = self.targetTransformer.transform(ntarget)\n",
    "if self.meta_mode == 'keras':\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "inputs = keras.Input(shape=(X.shape[1],))\n",
    "layer1 = layers.Dense(16, activation='relu')(inputs)\n",
    "layer2 = layers.Dense(8, activation='relu')(layer1)\n",
    "layer3 = layers.Dense(16, activation='relu')(layer2)\n",
    "classifier = layers.Dense(1, activation='softmax', name='method')(layer3)\n",
    "regressions = [layers.Dense(1, activation='linear', name=x)(layer3) for x in ntarget.columns.drop('method')]\n",
    "\n",
    "mdl = keras.Model(inputs=inputs, outputs=[classifier, *regressions])\n",
    "\n",
    "mdl.compile(loss=['categorical_crossentropy', *(['mse']*len(regressions))], optimizer='adam', metrics=['accuracy'])\n",
    "else:\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "mdl = MultiOutputRegressor(SVR())\n",
    "mdl.fit(X, y)\n",
    "self.ml = mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f91b223a9be7f82bfd164eb4b10e5e1c532d3ceac636b749a2ce370dda12911"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
